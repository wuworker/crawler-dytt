spring:
  application:
    name: dytt-crawler
  web:
    resources:
      static-locations: file:static/
  data:
    elasticsearch:
      repositories:
        enabled: false
  elasticsearch:
    rest:
      uris: http://localhost:9200
      connection-timeout: 5s
      read-timeout: 5s
  redis:
    host: localhost
    port: 6379
    database: 1
    timeout: 5s
    lettuce:
      pool:
        max-active: 16
        max-idle: 4
        min-idle: 1
        max-wait: 5s
  jackson:
    time-zone: GMT+8
    serialization:
      write-dates-as-timestamps: true
    default-property-inclusion: non_null

server:
  port: 8080
  error:
    whitelabel:
      enabled: false
  tomcat:
    connection-timeout: 5s
    threads:
      max: 100
    max-connections: 1000
  servlet:
    application-display-name: dytt-crawler-admin

logging:
  level:
    root: info
    com.wxl.dyttcrawler: debug

crawler:
  task-id: ${spring.application.name}
  start-url: "https://www.dytt8.net"
  allow-domains:
    - www.dytt8.net
#    - www.dytt8.com
#    - www.ygdy8.net
#    - www.ygdy8.com
#    - www.dydytt.net
  max-threads: 3
  concurrent-num: 1
  site:
    domain: "www.dytt8.net"
    charset: gbk
    sleep-time: 5s
    retry-times: 1
    timeout: 20s
    user-agent: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'
  download:
    ignore-ssl: true
    use-security: false
    pool:
      max-threads: 3
      keep-alive: 1m
      validate-after-inactivity: 30s
  scheduler:
    type: redis
  store:
    es:
      pool:
        max-threads: 3

